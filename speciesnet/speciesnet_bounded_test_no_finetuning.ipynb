{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uFTCwqrxGm_D"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_id = \"species_net_bounded\"\n",
    "num_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wi9vupvbFOBe",
    "outputId": "7e198ff7-94a4-460b-a569-b447bd4d329d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 ['IMG_0969.JPG', 'IMG_1685.JPG', 'IMG_0564.JPG', 'IMG_0558.JPG', 'IMG_1097.JPG', 'IMG_1040.JPG', 'IMG_0809.JPG', 'IMG_0606.JPG', 'IMG_0160.JPG', 'IMG_0161.JPG', 'IMG_0808.JPG', 'IMG_1096.JPG', 'IMG_0559.JPG', 'IMG_1690.JPG', 'IMG_0997.JPG', 'IMG_0015.JPG', 'IMG_0968.JPG', 'IMG_0017.JPG', 'IMG_1686.JPG', 'IMG_0598.JPG', 'IMG_1137.JPG', 'IMG_1094.JPG', 'IMG_0605.JPG', 'IMG_0162.JPG', 'IMG_1095.JPG', 'IMG_0599.JPG', 'IMG_1687.JPG', 'IMG_0016.JPG', 'IMG_0006.JPG', 'IMG_0562.JPG', 'IMG_0416.JPG', 'IMG_0600.JPG', 'IMG_1286.JPG', 'IMG_0417.JPG', 'IMG_0577.JPG', 'IMG_0563.JPG', 'IMG_0763.JPG', 'IMG_0549.JPG', 'IMG_0561.JPG', 'IMG_0159.JPG', 'IMG_0603.JPG', 'IMG_0158.JPG', 'IMG_1285.JPG', 'IMG_1093.JPG', 'IMG_0560.JPG', 'IMG_1332.JPG', 'IMG_1194.JPG', 'IMG_1180.JPG', 'IMG_1143.JPG', 'IMG_1037.JPG', 'IMG_1036.JPG', 'IMG_1142.JPG', 'IMG_1156.JPG', 'IMG_1181.JPG', 'IMG_1195.JPG', 'IMG_1183.JPG', 'IMG_1197.JPG', 'IMG_1168.JPG', 'IMG_1008.JPG', 'IMG_1034.JPG', 'IMG_1020.JPG', 'IMG_1035.JPG', 'IMG_1009.JPG', 'IMG_1155.JPG', 'IMG_1141.JPG', 'IMG_1169.JPG', 'IMG_1196.JPG', 'IMG_1182.JPG', 'IMG_1186.JPG', 'IMG_1192.JPG', 'IMG_1145.JPG', 'IMG_1637.JPG', 'IMG_1179.JPG', 'IMG_1019.JPG', 'IMG_1597.JPG', 'IMG_1018.JPG', 'IMG_1178.JPG', 'IMG_1144.JPG', 'IMG_1193.JPG', 'IMG_1187.JPG', 'IMG_1191.JPG', 'IMG_1185.JPG', 'IMG_1146.JPG', 'IMG_0258.JPG', 'IMG_1033.JPG', 'IMG_0271.JPG', 'IMG_0259.JPG', 'IMG_1147.JPG', 'IMG_1184.JPG', 'IMG_1190.JPG', 'IMG_1189.JPG', 'IMG_0254.JPG', 'IMG_1176.JPG', 'IMG_1604.JPG', 'IMG_1002.JPG', 'IMG_1016.JPG', 'IMG_1599.JPG', 'IMG_1200.JPG', 'IMG_1201.JPG', 'IMG_1598.JPG', 'IMG_1017.JPG', 'IMG_1003.JPG', 'IMG_1177.JPG', 'IMG_0255.JPG', 'IMG_1188.JPG', 'IMG_0257.JPG', 'IMG_1175.JPG', 'IMG_1613.JPG', 'IMG_1015.JPG', 'IMG_1001.JPG', 'IMG_1203.JPG', 'IMG_1202.JPG', 'IMG_1000.JPG', 'IMG_1014.JPG', 'IMG_1174.JPG', 'IMG_0256.JPG', 'IMG_1148.JPG', 'IMG_1602.JPG', 'IMG_1170.JPG', 'IMG_0252.JPG', 'IMG_1010.JPG', 'IMG_1004.JPG', 'IMG_1038.JPG', 'IMG_1039.JPG', 'IMG_1005.JPG', 'IMG_1011.JPG', 'IMG_0253.JPG', 'IMG_0247.JPG', 'IMG_1171.JPG', 'IMG_1165.JPG', 'IMG_1603.JPG', 'IMG_1198.JPG', 'IMG_1173.JPG', 'IMG_1601.JPG', 'IMG_1167.JPG', 'IMG_0251.JPG', 'IMG_1007.JPG', 'IMG_1013.JPG', 'IMG_1204.JPG', 'IMG_1012.JPG', 'IMG_1006.JPG', 'IMG_1600.JPG', 'IMG_1166.JPG', 'IMG_1172.JPG', 'IMG_1199.JPG', 'IMG_0551.JPG', 'IMG_0579.JPG', 'IMG_1101.JPG', 'IMG_0425.JPG', 'IMG_0182.JPG', 'IMG_1288.JPG', 'IMG_0155.JPG', 'IMG_0418.JPG', 'IMG_0424.JPG', 'IMG_0578.JPG', 'IMG_1100.JPG', 'IMG_0236.JPG', 'IMG_0550.JPG', 'IMG_1316.JPG', 'IMG_1314.JPG', 'IMG_0552.JPG', 'IMG_1102.JPG', 'IMG_0426.JPG', 'IMG_0181.JPG', 'IMG_0156.JPG', 'IMG_0157.JPG', 'IMG_0180.JPG', 'IMG_1103.JPG', 'IMG_0553.JPG', 'IMG_0584.JPG', 'IMG_1329.JPG', 'IMG_0966.JPG', 'IMG_0972.JPG', 'IMG_0999.JPG', 'IMG_0557.JPG', 'IMG_1098.JPG', 'IMG_0423.JPG', 'IMG_0812.JPG', 'IMG_0806.JPG', 'IMG_0153.JPG', 'IMG_0608.JPG', 'IMG_0807.JPG', 'IMG_0422.JPG', 'IMG_1099.JPG', 'IMG_0556.JPG', 'IMG_0581.JPG', 'IMG_0998.JPG', 'IMG_0967.JPG', 'IMG_0971.JPG', 'IMG_0965.JPG', 'IMG_0018.JPG', 'IMG_1689.JPG', 'IMG_0583.JPG', 'IMG_1104.JPG', 'IMG_0554.JPG', 'IMG_0420.JPG', 'IMG_0805.JPG', 'IMG_0811.JPG', 'IMG_0179.JPG', 'IMG_0810.JPG', 'IMG_0555.JPG', 'IMG_1105.JPG', 'IMG_0582.JPG', 'IMG_1688.JPG', 'IMG_1313.JPG', 'IMG_0970.JPG']\n",
      "447 ['IMG_0941.JPG', 'IMG_0996.JPG', 'IMG_1450.JPG', 'IMG_3535.JPG', 'IMG_0982.JPG', 'IMG_1444.JPG', 'IMG_1134.JPG', 'IMG_1120.JPG', 'IMG_0389.JPG', 'IMG_0404.JPG', 'IMG_1726.JPG', 'IMG_1732.JPG', 'IMG_0148.JPG', 'IMG_0149.JPG', 'IMG_1733.JPG', 'IMG_1727.JPG', 'IMG_0405.JPG', 'IMG_0388.JPG', 'IMG_1121.JPG', 'IMG_1135.JPG', 'IMG_0217.JPG', 'IMG_1109.JPG', 'IMG_3534.JPG', 'IMG_1445.JPG', 'IMG_0983.JPG', 'IMG_1451.JPG', 'IMG_0942.JPG', 'IMG_0981.JPG', 'IMG_1447.JPG', 'IMG_3536.JPG', 'IMG_0995.JPG', 'IMG_1453.JPG', 'IMG_0349.JPG', 'IMG_1731.JPG', 'IMG_1725.JPG', 'IMG_0639.JPG', 'IMG_0638.JPG', 'IMG_0348.JPG', 'IMG_1730.JPG', 'IMG_1136.JPG', 'IMG_1122.JPG', 'IMG_2371.JPG', 'IMG_1693.JPG', 'IMG_1452.JPG', 'IMG_0994.JPG', 'IMG_1446.JPG', 'IMG_0980.JPG', 'IMG_3537.JPG', 'IMG_0943.JPG', 'IMG_0947.JPG', 'IMG_3533.JPG', 'IMG_1442.JPG', 'IMG_1456.JPG', 'IMG_0990.JPG', 'IMG_0748.JPG', 'IMG_1697.JPG', 'IMG_1126.JPG', 'IMG_1132.JPG', 'IMG_1734.JPG', 'IMG_0402.JPG', 'IMG_0403.JPG', 'IMG_1735.JPG', 'IMG_1133.JPG', 'IMG_1127.JPG', 'IMG_1696.JPG', 'IMG_0991.JPG', 'IMG_3532.JPG', 'IMG_1443.JPG', 'IMG_0946.JPG', 'IMG_0944.JPG', 'IMG_0978.JPG', 'IMG_1455.JPG', 'IMG_0993.JPG', 'IMG_1441.JPG', 'IMG_3530.JPG', 'IMG_1694.JPG', 'IMG_1131.JPG', 'IMG_1125.JPG', 'IMG_1643.JPG', 'IMG_1119.JPG', 'IMG_0401.JPG', 'IMG_1118.JPG', 'IMG_1130.JPG', 'IMG_1695.JPG', 'IMG_1440.JPG', 'IMG_3531.JPG', 'IMG_0992.JPG', 'IMG_1454.JPG', 'IMG_0979.JPG', 'IMG_0945.JPG', 'IMG_3581.JPG', 'IMG_4588.JPG', 'IMG_3595.JPG', 'IMG_4577.JPG', 'IMG_3542.JPG', 'IMG_1433.JPG', 'IMG_3230.JPG', 'IMG_3556.JPG', 'IMG_0513.JPG', 'IMG_0261.JPG', 'IMG_0507.JPG', 'IMG_2338.JPG', 'IMG_0249.JPG', 'IMG_0498.JPG', 'IMG_1792.JPG', 'IMG_2516.JPG', 'IMG_0315.JPG', 'IMG_0329.JPG', 'IMG_1584.JPG', 'IMG_1590.JPG', 'IMG_0103.JPG', 'IMG_0117.JPG', 'IMG_1221.JPG', 'IMG_0116.JPG', 'IMG_0102.JPG', 'IMG_1591.JPG', 'IMG_1585.JPG', 'IMG_3621.JPG', 'IMG_0314.JPG', 'IMG_0472.JPG', 'IMG_2517.JPG', 'IMG_1793.JPG', 'IMG_0499.JPG', 'IMG_2339.JPG', 'IMG_0260.JPG', 'IMG_0506.JPG', 'IMG_0512.JPG', 'IMG_3231.JPG', 'IMG_3557.JPG', 'IMG_3543.JPG', 'IMG_3225.JPG', 'IMG_4576.JPG', 'IMG_3594.JPG', 'IMG_3580.JPG', 'IMG_4589.JPG', 'IMG_3596.JPG', 'IMG_3582.JPG', 'IMG_3569.JPG', 'IMG_4574.JPG', 'IMG_3555.JPG', 'IMG_3233.JPG', 'IMG_3227.JPG', 'IMG_3541.JPG', 'IMG_0504.JPG', 'IMG_0262.JPG', 'IMG_0510.JPG', 'IMG_1791.JPG', 'IMG_0316.JPG', 'IMG_2515.JPG', 'IMG_3623.JPG', 'IMG_1593.JPG', 'IMG_1587.JPG', 'IMG_0114.JPG', 'IMG_0100.JPG', 'IMG_1579.JPG', 'IMG_0101.JPG', 'IMG_0115.JPG', 'IMG_1586.JPG', 'IMG_1592.JPG', 'IMG_3622.JPG', 'IMG_2514.JPG', 'IMG_0317.JPG', 'IMG_1790.JPG', 'IMG_0511.JPG', 'IMG_0505.JPG', 'IMG_0263.JPG', 'IMG_3226.JPG', 'IMG_3540.JPG', 'IMG_3554.JPG', 'IMG_3232.JPG', 'IMG_4575.JPG', 'IMG_3568.JPG', 'IMG_3583.JPG', 'IMG_3597.JPG', 'IMG_3593.JPG', 'IMG_3587.JPG', 'IMG_3550.JPG', 'IMG_1435.JPG', 'IMG_3578.JPG', 'IMG_0717.JPG', 'IMG_4571.JPG', 'IMG_1637.JPG', 'IMG_1151.JPG', 'IMG_0267.JPG', 'IMG_0501.JPG', 'IMG_0515.JPG', 'IMG_1794.JPG', 'IMG_3626.JPG', 'IMG_0449.JPG', 'IMG_0313.JPG', 'IMG_0475.JPG', 'IMG_1596.JPG', 'IMG_1582.JPG', 'IMG_0111.JPG', 'IMG_0104.JPG', 'IMG_0110.JPG', 'IMG_1583.JPG', 'IMG_1597.JPG', 'IMG_0474.JPG', 'IMG_3627.JPG', 'IMG_1795.JPG', 'IMG_0514.JPG', 'IMG_0272.JPG', 'IMG_0266.JPG', 'IMG_0500.JPG', 'IMG_1150.JPG', 'IMG_3579.JPG', 'IMG_4570.JPG', 'IMG_3545.JPG', 'IMG_1434.JPG', 'IMG_3551.JPG', 'IMG_3586.JPG', 'IMG_3592.JPG', 'IMG_3584.JPG', 'IMG_0099.JPG', 'IMG_3590.JPG', 'IMG_1436.JPG', 'IMG_0728.JPG', 'IMG_3547.JPG', 'IMG_3553.JPG', 'IMG_4572.JPG', 'IMG_0258.JPG', 'IMG_0270.JPG', 'IMG_0516.JPG', 'IMG_0502.JPG', 'IMG_0264.JPG', 'IMG_3631.JPG', 'IMG_0338.JPG', 'IMG_2513.JPG', 'IMG_3619.JPG', 'IMG_1581.JPG', 'IMG_1595.JPG', 'IMG_0113.JPG', 'IMG_1594.JPG', 'IMG_1580.JPG', 'IMG_3624.JPG', 'IMG_0339.JPG', 'IMG_3630.JPG', 'IMG_1796.JPG', 'IMG_0503.JPG', 'IMG_0265.JPG', 'IMG_0271.JPG', 'IMG_0517.JPG', 'IMG_0259.JPG', 'IMG_4573.JPG', 'IMG_0729.JPG', 'IMG_1437.JPG', 'IMG_3546.JPG', 'IMG_3591.JPG', 'IMG_0098.JPG', 'IMG_3585.JPG', 'IMG_4581.JPG', 'IMG_3588.JPG', 'IMG_0730.JPG', 'IMG_0724.JPG', 'IMG_3563.JPG', 'IMG_0718.JPG', 'IMG_3577.JPG', 'IMG_0268.JPG', 'IMG_3629.JPG', 'IMG_0320.JPG', 'IMG_0334.JPG', 'IMG_0452.JPG', 'IMG_1599.JPG', 'IMG_0644.JPG', 'IMG_0876.JPG', 'IMG_0862.JPG', 'IMG_1598.JPG', 'IMG_3600.JPG', 'IMG_0335.JPG', 'IMG_0453.JPG', 'IMG_3628.JPG', 'IMG_0269.JPG', 'IMG_0241.JPG', 'IMG_0719.JPG', 'IMG_3576.JPG', 'IMG_3562.JPG', 'IMG_0725.JPG', 'IMG_0731.JPG', 'IMG_4580.JPG', 'IMG_3589.JPG', 'IMG_0082.JPG', 'IMG_4582.JPG', 'IMG_3548.JPG', 'IMG_1439.JPG', 'IMG_0727.JPG', 'IMG_3574.JPG', 'IMG_4569.JPG', 'IMG_3560.JPG', 'IMG_1149.JPG', 'IMG_0257.JPG', 'IMG_0519.JPG', 'IMG_0451.JPG', 'IMG_0337.JPG', 'IMG_2520.JPG', 'IMG_0109.JPG', 'IMG_0108.JPG', 'IMG_0646.JPG', 'IMG_0120.JPG', 'IMG_0861.JPG', 'IMG_0875.JPG', 'IMG_3617.JPG', 'IMG_0450.JPG', 'IMG_0518.JPG', 'IMG_0242.JPG', 'IMG_3561.JPG', 'IMG_3575.JPG', 'IMG_3549.JPG', 'IMG_0726.JPG', 'IMG_1438.JPG', 'IMG_0097.JPG', 'IMG_4583.JPG', 'IMG_4587.JPG', 'IMG_4578.JPG', 'IMG_3571.JPG', 'IMG_3565.JPG', 'IMG_0722.JPG', 'IMG_3559.JPG', 'IMG_1602.JPG', 'IMG_0508.JPG', 'IMG_2337.JPG', 'IMG_0520.JPG', 'IMG_0497.JPG', 'IMG_1789.JPG', 'IMG_2519.JPG', 'IMG_0332.JPG', 'IMG_0118.JPG', 'IMG_0642.JPG', 'IMG_0643.JPG', 'IMG_0119.JPG', 'IMG_0333.JPG', 'IMG_2518.JPG', 'IMG_0509.JPG', 'IMG_3558.JPG', 'IMG_0723.JPG', 'IMG_3564.JPG', 'IMG_4579.JPG', 'IMG_3570.JPG', 'IMG_4592.JPG', 'IMG_4586.JPG', 'IMG_4590.JPG', 'IMG_3599.JPG', 'IMG_4584.JPG', 'IMG_3566.JPG', 'IMG_3572.JPG', 'IMG_0721.JPG', 'IMG_3228.JPG', 'IMG_1601.JPG', 'IMG_0251.JPG', 'IMG_0319.JPG', 'IMG_0331.JPG', 'IMG_1588.JPG', 'IMG_0669.JPG', 'IMG_0641.JPG', 'IMG_0640.JPG', 'IMG_1589.JPG', 'IMG_0873.JPG', 'IMG_0330.JPG', 'IMG_0318.JPG', 'IMG_5506.JPG', 'IMG_1600.JPG', 'IMG_3229.JPG', 'IMG_0720.JPG', 'IMG_3573.JPG', 'IMG_3567.JPG', 'IMG_4591.JPG', 'IMG_3598.JPG', 'IMG_0948.JPG', 'IMG_0974.JPG', 'IMG_0747.JPG', 'IMG_1698.JPG', 'IMG_1129.JPG', 'IMG_0223.JPG', 'IMG_1115.JPG', 'IMG_0394.JPG', 'IMG_0343.JPG', 'IMG_2018.JPG', 'IMG_2019.JPG', 'IMG_0342.JPG', 'IMG_0395.JPG', 'IMG_1114.JPG', 'IMG_0222.JPG', 'IMG_1128.JPG', 'IMG_1699.JPG', 'IMG_3529.JPG', 'IMG_0746.JPG', 'IMG_0975.JPG', 'IMG_0977.JPG', 'IMG_0744.JPG', 'IMG_0220.JPG', 'IMG_1116.JPG', 'IMG_0397.JPG', 'IMG_0354.JPG', 'IMG_0340.JPG', 'IMG_0341.JPG', 'IMG_0355.JPG', 'IMG_0396.JPG', 'IMG_1117.JPG', 'IMG_2344.JPG', 'IMG_0221.JPG', 'IMG_0989.JPG', 'IMG_0745.JPG', 'IMG_0976.JPG', 'IMG_0741.JPG', 'IMG_0219.JPG', 'IMG_1113.JPG', 'IMG_2340.JPG', 'IMG_0392.JPG', 'IMG_0386.JPG', 'IMG_1701.JPG', 'IMG_1729.JPG', 'IMG_0351.JPG', 'IMG_0345.JPG', 'IMG_2022.JPG', 'IMG_0147.JPG', 'IMG_0152.JPG', 'IMG_0344.JPG', 'IMG_1728.JPG', 'IMG_0350.JPG', 'IMG_1700.JPG', 'IMG_0387.JPG', 'IMG_0393.JPG', 'IMG_2341.JPG', 'IMG_0224.JPG', 'IMG_1112.JPG', 'IMG_0218.JPG', 'IMG_0973.JPG', 'IMG_3539.JPG', 'IMG_1448.JPG', 'IMG_0742.JPG', 'IMG_1110.JPG', 'IMG_2343.JPG', 'IMG_0385.JPG', 'IMG_0391.JPG', 'IMG_0346.JPG', 'IMG_0352.JPG', 'IMG_0637.JPG', 'IMG_0151.JPG', 'IMG_0145.JPG', 'IMG_0353.JPG', 'IMG_0347.JPG', 'IMG_0390.JPG', 'IMG_2342.JPG', 'IMG_1111.JPG', 'IMG_0743.JPG', 'IMG_3538.JPG', 'IMG_1449.JPG']\n"
     ]
    }
   ],
   "source": [
    "# get image filepaths\n",
    "pangolin_path = \"[6-22] Bounded Pangolin Images\"\n",
    "other_path = \"[6-22] Bounded Other Animal Images\"\n",
    "\n",
    "pangolin_images = os.listdir(pangolin_path)\n",
    "other_images = os.listdir(other_path)\n",
    "print(len(pangolin_images), pangolin_images)\n",
    "print(len(other_images), other_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4qGIAA6iKjH",
    "outputId": "8d9f9612-1072-414d-a408-917197573be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[6-22] Bounded Pangolin Images/IMG_0969.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1685.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0564.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0558.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1097.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1040.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0809.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0606.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0160.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0161.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0808.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1096.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0559.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1690.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0997.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0015.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0968.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0017.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1686.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0598.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1137.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1094.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0605.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0162.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1095.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0599.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1687.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0016.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0006.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0562.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0416.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0600.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1286.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0417.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0577.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0563.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0763.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0549.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0561.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0159.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0603.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0158.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1285.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1093.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0560.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1332.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1194.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1180.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1143.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1037.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1036.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1142.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1156.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1181.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1195.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1183.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1197.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1168.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1008.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1034.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1020.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1035.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1009.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1155.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1141.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1169.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1196.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1182.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1186.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1192.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1145.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1637.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1179.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1019.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1597.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1018.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1178.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1144.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1193.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1187.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1191.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1185.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1146.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0258.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1033.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0271.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0259.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1147.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1184.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1190.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1189.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0254.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1176.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1604.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1002.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1016.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1599.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1200.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1201.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1598.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1017.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1003.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1177.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0255.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1188.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0257.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1175.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1613.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1015.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1001.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1203.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1202.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1000.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1014.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1174.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0256.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1148.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1602.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1170.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0252.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1010.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1004.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1038.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1039.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1005.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1011.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0253.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0247.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1171.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1165.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1603.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1198.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1173.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1601.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1167.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0251.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1007.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1013.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1204.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1012.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1006.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1600.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1166.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1172.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1199.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0551.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0579.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1101.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0425.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0182.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1288.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0155.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0418.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0424.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0578.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1100.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0236.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0550.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1316.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1314.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0552.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1102.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0426.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0181.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0156.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0157.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0180.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1103.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0553.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0584.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1329.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0966.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0972.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0999.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0557.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1098.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0423.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0812.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0806.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0153.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0608.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0807.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0422.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1099.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0556.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0581.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0998.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0967.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0971.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0965.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0018.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1689.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0583.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1104.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0554.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0420.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0805.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0811.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0179.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0810.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0555.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1105.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0582.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1688.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_1313.JPG', 1), ('[6-22] Bounded Pangolin Images/IMG_0970.JPG', 1), ('[6-22] Bounded Other Animal Images/IMG_0941.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0996.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1450.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3535.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0982.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1444.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1134.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1120.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0389.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0404.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1726.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1732.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0148.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0149.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1733.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1727.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0405.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0388.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1121.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1135.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0217.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1109.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3534.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1445.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0983.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1451.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0942.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0981.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1447.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3536.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0995.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1453.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0349.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1731.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1725.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0639.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0638.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0348.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1730.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1136.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1122.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2371.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1693.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1452.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0994.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1446.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0980.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3537.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0943.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0947.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3533.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1442.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1456.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0990.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0748.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1697.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1126.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1132.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1734.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0402.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0403.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1735.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1133.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1127.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1696.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0991.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3532.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1443.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0946.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0944.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0978.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1455.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0993.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1441.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3530.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1694.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1131.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1125.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1643.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1119.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0401.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1118.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1130.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1695.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1440.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3531.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0992.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1454.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0979.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0945.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3581.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4588.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3595.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4577.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3542.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1433.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3230.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3556.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0513.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0261.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0507.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2338.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0249.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0498.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1792.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2516.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0315.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0329.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1584.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1590.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0103.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0117.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1221.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0116.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0102.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1591.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1585.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3621.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0314.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0472.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2517.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1793.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0499.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2339.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0260.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0506.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0512.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3231.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3557.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3543.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3225.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4576.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3594.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3580.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4589.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3596.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3582.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3569.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4574.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3555.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3233.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3227.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3541.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0504.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0262.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0510.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1791.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0316.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2515.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3623.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1593.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1587.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0114.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0100.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1579.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0101.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0115.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1586.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1592.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3622.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2514.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0317.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1790.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0511.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0505.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0263.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3226.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3540.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3554.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3232.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4575.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3568.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3583.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3597.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3593.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3587.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3550.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1435.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3578.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0717.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4571.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1637.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1151.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0267.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0501.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0515.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1794.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3626.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0449.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0313.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0475.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1596.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1582.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0111.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0104.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0110.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1583.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1597.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0474.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3627.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1795.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0514.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0272.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0266.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0500.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1150.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3579.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4570.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3545.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1434.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3551.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3586.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3592.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3584.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0099.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3590.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1436.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0728.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3547.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3553.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4572.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0258.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0270.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0516.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0502.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0264.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3631.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0338.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2513.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3619.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1581.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1595.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0113.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1594.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1580.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3624.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0339.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3630.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1796.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0503.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0265.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0271.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0517.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0259.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4573.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0729.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1437.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3546.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3591.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0098.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3585.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4581.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3588.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0730.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0724.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3563.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0718.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3577.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0268.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3629.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0320.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0334.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0452.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1599.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0644.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0876.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0862.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1598.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3600.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0335.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0453.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3628.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0269.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0241.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0719.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3576.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3562.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0725.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0731.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4580.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3589.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0082.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4582.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3548.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1439.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0727.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3574.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4569.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3560.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1149.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0257.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0519.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0451.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0337.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2520.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0109.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0108.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0646.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0120.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0861.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0875.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3617.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0450.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0518.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0242.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3561.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3575.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3549.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0726.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1438.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0097.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4583.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4587.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4578.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3571.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3565.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0722.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3559.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1602.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0508.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2337.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0520.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0497.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1789.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2519.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0332.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0118.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0642.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0643.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0119.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0333.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2518.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0509.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3558.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0723.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3564.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4579.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3570.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4592.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4586.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4590.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3599.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4584.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3566.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3572.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0721.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3228.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1601.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0251.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0319.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0331.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1588.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0669.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0641.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0640.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1589.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0873.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0330.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0318.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_5506.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1600.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3229.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0720.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3573.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3567.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_4591.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3598.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0948.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0974.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0747.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1698.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1129.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0223.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1115.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0394.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0343.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2018.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2019.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0342.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0395.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1114.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0222.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1128.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1699.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3529.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0746.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0975.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0977.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0744.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0220.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1116.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0397.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0354.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0340.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0341.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0355.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0396.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1117.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2344.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0221.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0989.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0745.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0976.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0741.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0219.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1113.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2340.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0392.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0386.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1701.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1729.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0351.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0345.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2022.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0147.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0152.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0344.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1728.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0350.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1700.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0387.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0393.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2341.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0224.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1112.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0218.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0973.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3539.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1448.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0742.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1110.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2343.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0385.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0391.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0346.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0352.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0637.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0151.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0145.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0353.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0347.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0390.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_2342.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1111.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_0743.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_3538.JPG', 0), ('[6-22] Bounded Other Animal Images/IMG_1449.JPG', 0)]\n",
      "653\n"
     ]
    }
   ],
   "source": [
    "# combine filepath and label\n",
    "data = ([(os.path.join(pangolin_path, img), 1) for img in pangolin_images if img != \".DS_Store\"] +\n",
    "    [(os.path.join(other_path, img), 0) for img in other_images])\n",
    "\n",
    "print(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YebF1-NvA-NQ",
    "outputId": "60dc5451-d3b5-4521-c531-292d078236f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and write column headers to csv files for logging purposes\n",
    "import csv\n",
    "log_folder_path = \"./log/\" + program_id + \"/\"\n",
    "os.makedirs(log_folder_path, exist_ok=True)\n",
    "\n",
    "train_csv_file_path = log_folder_path + \"train_scores.csv\"\n",
    "val_csv_file_path = log_folder_path + \"val_scores.csv\"\n",
    "time_csv_file_path = log_folder_path + \"time_per_epoch.csv\"\n",
    "test_csv_file_path = log_folder_path + \"test_scores.csv\"\n",
    "loss_csv_file_path = log_folder_path + \"loss_per_epoch.csv\"\n",
    "\n",
    "train_csv = open(train_csv_file_path, mode='w', newline='')\n",
    "val_csv = open(val_csv_file_path, mode='w', newline='')\n",
    "time_csv = open(time_csv_file_path, mode='w', newline='')\n",
    "test_csv = open(test_csv_file_path, mode='w', newline='')\n",
    "loss_csv = open(loss_csv_file_path, mode='w', newline='')\n",
    "\n",
    "train_writer = csv.writer(train_csv)\n",
    "val_writer = csv.writer(val_csv)\n",
    "time_writer = csv.writer(time_csv)\n",
    "test_writer = csv.writer(test_csv)\n",
    "loss_writer = csv.writer(loss_csv)\n",
    "\n",
    "train_writer.writerow([\n",
    "    'fold', 'epoch',\n",
    "    'accuracy_pangolin', 'accuracy_other',\n",
    "    'recall_pangolin', 'recall_other',\n",
    "    'precision_pangolin', 'precision_other',\n",
    "    'f1_pangolin', 'f1_other',\n",
    "    'auc_pangolin', 'auc_other'\n",
    "])\n",
    "val_writer.writerow([\n",
    "    'fold', 'epoch',\n",
    "    'accuracy_pangolin', 'accuracy_other',\n",
    "    'recall_pangolin', 'recall_other',\n",
    "    'precision_pangolin', 'precision_other',\n",
    "    'f1_pangolin', 'f1_other',\n",
    "    'auc_pangolin', 'auc_other'\n",
    "])\n",
    "time_writer.writerow(['fold', 'epoch', 'time'])\n",
    "test_writer.writerow([\n",
    "    'fold',\n",
    "    'accuracy_pangolin', 'accuracy_other',\n",
    "    'recall_pangolin', 'recall_other',\n",
    "    'precision_pangolin', 'precision_other',\n",
    "    'f1_pangolin', 'f1_other',\n",
    "    'auc_pangolin', 'auc_other'\n",
    "])\n",
    "loss_writer.writerow(['fold', 'epoch', 'train_loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FNLWFI5Mc3YA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "misclassified_folder_path = \"./misclassified/\" + program_id + \"/\"\n",
    "os.makedirs(misclassified_folder_path, exist_ok=True)\n",
    "\n",
    "# plot image of misclassifications\n",
    "def plot_misclassified(fold, pred, data):\n",
    "    true = [label for _, label in data]\n",
    "    fn_indices = [i for i, (p, t) in enumerate(zip(pred, true)) if p == 0 and t == 1]   # false negatives\n",
    "    fp_indices = [i for i, (p, t) in enumerate(zip(pred, true)) if p == 1 and t == 0]   # false positives\n",
    "\n",
    "    # helper method to plot image\n",
    "    def plot_images(indices, title):\n",
    "        if not indices:\n",
    "            print(f\"No Misclassified Samples Found: \" + title)\n",
    "            return\n",
    "        \n",
    "        print(f\"Misclassified Samples Found: \" + str(len(indices)))\n",
    "        indices = indices[:5]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, len(indices), figsize=(15, 5))\n",
    "        if len(indices) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for ax, idx in zip(axes, indices):\n",
    "            filename, true_label = data[idx]\n",
    "            img = Image.open(filename).convert(\"L\")            \n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "            ax.set_title(f\"{title}\\nPred: {pred[idx]}, True: {true_label}\", fontsize=10)\n",
    "            \n",
    "            misclassified_image_path  = misclassified_folder_path + \"misclassified_fold_\" + str(fold + 1) + \"/\"     # path to store the misclassified images, name-specific to fold \n",
    "            misclassified_image = misclassified_image_path + str(idx) + \".png\"\n",
    "\n",
    "            os.makedirs(misclassified_image_path, exist_ok=True)\n",
    "            plt.savefig(misclassified_image, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "    # plot images\n",
    "    plot_images(fn_indices, \"Fold \" + str(fold + 1) + \"- False Negatives\")\n",
    "    print(fn_indices)\n",
    "    plot_images(fp_indices, \"Fold \" + str(fold + 1) + \"- False Positives\")\n",
    "    print(fp_indices)\n",
    "\n",
    "###############################################################################################################################################\n",
    "# printing/logging methods (different for validation, training, and testing because they have different ways to log to csv files)\n",
    "###############################################################################################################################################\n",
    "\n",
    "# prints score for validation\n",
    "def val_print_and_log_scores(fold, epoch, true, pred, prob):\n",
    "    # calculating scores for pangolin class\n",
    "    accuracy = accuracy_score(true, pred)\n",
    "    pangolin_precision = precision_score(true, pred, pos_label=1, zero_division=0)\n",
    "    pangolin_recall = recall_score(true, pred, pos_label=1, zero_division=0)\n",
    "    pangolin_f1 = f1_score(true, pred, pos_label=1, zero_division=0)\n",
    "    pangolin_prob = prob\n",
    "    pangolin_auc = roc_auc_score(true, pangolin_prob)\n",
    "\n",
    "    print(f\"\\tpangolin accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\tpangolin precision: {pangolin_precision:.4f}\")\n",
    "    print(f\"\\tpangolin recall: {pangolin_recall:.4f}\")\n",
    "    print(f\"\\tpangolin f1-score: {pangolin_f1:.4f}\")\n",
    "    print(f\"\\tpangolin auc: {pangolin_auc:.4f}\")\n",
    "\n",
    "    # calculating scores for other class\n",
    "    other_precision = precision_score(true, pred, pos_label=0, zero_division=0)\n",
    "    other_recall = recall_score(true, pred, pos_label=0, zero_division=0)\n",
    "    other_f1 = f1_score(true, pred, pos_label=0, zero_division=0)\n",
    "\n",
    "    other_prob = prob\n",
    "    true_inverted = [1 if t != 1 else 0 for t in true]\n",
    "    other_auc = roc_auc_score(true_inverted, other_prob)\n",
    "\n",
    "    print(f\"\\tother accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\tother precision: {other_precision:.4f}\")\n",
    "    print(f\"\\tother recall: {other_recall:.4f}\")\n",
    "    print(f\"\\tother f1-score: {other_f1:.4f}\")\n",
    "    print(f\"\\tother auc: {other_auc:.4f}\")\n",
    "\n",
    "    # writing to csv file\n",
    "    val_writer.writerow([\n",
    "            fold, epoch,\n",
    "            accuracy, accuracy,\n",
    "            pangolin_recall, other_recall,\n",
    "            pangolin_precision, other_precision,\n",
    "            pangolin_f1, other_f1,\n",
    "            pangolin_auc, other_auc\n",
    "    ])\n",
    "\n",
    "\n",
    "# print and log score for training\n",
    "def train_print_and_log_scores(fold, epoch, true, pred, prob):\n",
    "    # calculating scores for pangolin class\n",
    "    accuracy = accuracy_score(true, pred)\n",
    "    pangolin_precision = precision_score(true, pred, pos_label=1, zero_division=0)\n",
    "    pangolin_recall = recall_score(true, pred, pos_label=1, zero_division=0)\n",
    "    pangolin_f1 = f1_score(true, pred, pos_label=1, zero_division=0)\n",
    "    pangolin_prob = prob.detach().numpy()\n",
    "    pangolin_auc = roc_auc_score(true, pangolin_prob)\n",
    "\n",
    "    print(f\"\\tpangolin accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\tpangolin precision: {pangolin_precision:.4f}\")\n",
    "    print(f\"\\tpangolin recall: {pangolin_recall:.4f}\")\n",
    "    print(f\"\\tpangolin f1-score: {pangolin_f1:.4f}\")\n",
    "    print(f\"\\tpangolin auc: {pangolin_auc:.4f}\")\n",
    "\n",
    "    # calculating scores for other class\n",
    "    other_precision = precision_score(true, pred, pos_label=0, zero_division=0)\n",
    "    other_recall = recall_score(true, pred, pos_label=0, zero_division=0)\n",
    "    other_f1 = f1_score(true, pred, pos_label=0, zero_division=0)\n",
    "    other_prob = prob.detach().numpy()\n",
    "    true_inverted = (true != 1).detach().numpy().astype(int)  \n",
    "    other_auc = roc_auc_score(true_inverted, other_prob)\n",
    "\n",
    "    print(f\"\\tother accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\tother precision: {other_precision:.4f}\")\n",
    "    print(f\"\\tother recall: {other_recall:.4f}\")\n",
    "    print(f\"\\tother f1-score: {other_f1:.4f}\")\n",
    "    print(f\"\\tother auc: {other_auc:.4f}\")\n",
    "\n",
    "    # writing to csv file\n",
    "    train_writer.writerow([\n",
    "        fold, epoch,\n",
    "        accuracy, accuracy,\n",
    "        pangolin_recall, other_recall,\n",
    "        pangolin_precision, other_precision,\n",
    "        pangolin_f1, other_f1,\n",
    "        pangolin_auc, other_auc\n",
    "    ])\n",
    "\n",
    "# print and log scores for testing\n",
    "def test_print_and_log_scores(fold, true, pred, prob):\n",
    "    # calculating scores for pangolin class\n",
    "    accuracy = accuracy_score(true, pred)\n",
    "    pangolin_precision = precision_score(true, pred, pos_label=1, zero_division=0)\n",
    "    pangolin_recall = recall_score(true, pred, pos_label=1, zero_division=0)\n",
    "    pangolin_f1 = f1_score(true, pred, pos_label=1, zero_division=0)\n",
    "    pangolin_prob = prob\n",
    "    pangolin_auc = roc_auc_score(true, pangolin_prob)\n",
    "\n",
    "    print(f\"\\tpangolin accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\tpangolin precision: {pangolin_precision:.4f}\")\n",
    "    print(f\"\\tpangolin recall: {pangolin_recall:.4f}\")\n",
    "    print(f\"\\tpangolin f1-score: {pangolin_f1:.4f}\")\n",
    "    print(f\"\\tpangolin auc: {pangolin_auc:.4f}\")\n",
    "\n",
    "    # calculating scores for other class\n",
    "    other_precision = precision_score(true, pred, pos_label=0, zero_division=0)\n",
    "    other_recall = recall_score(true, pred, pos_label=0, zero_division=0)\n",
    "    other_f1 = f1_score(true, pred, pos_label=0, zero_division=0)\n",
    "    other_prob = prob\n",
    "    true_inverted = [1 if t != 1 else 0 for t in true]\n",
    "    other_auc = roc_auc_score(true_inverted, other_prob)\n",
    "\n",
    "    print(f\"\\tother accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\tother precision: {other_precision:.4f}\")\n",
    "    print(f\"\\tother recall: {other_recall:.4f}\")\n",
    "    print(f\"\\tother f1-score: {other_f1:.4f}\")\n",
    "    print(f\"\\tother auc: {other_auc:.4f}\")\n",
    "\n",
    "    # writing to csv file\n",
    "    test_writer.writerow([\n",
    "        fold,\n",
    "        accuracy, accuracy,\n",
    "        pangolin_recall, other_recall,\n",
    "        pangolin_precision, other_precision,\n",
    "        pangolin_f1, other_f1,\n",
    "        pangolin_auc, other_auc\n",
    "    ])\n",
    "\n",
    "# custom collate function for the data loader\n",
    "def collate_fn(batch):\n",
    "    images = torch.stack([item[\"image\"] for item in batch])\n",
    "    labels = torch.tensor([item[\"label\"] for item in batch], dtype=torch.long)\n",
    "    image_ids = [item[\"image_id\"] for item in batch]\n",
    "\n",
    "    return {\"image\": images, \"label\": labels, \"image_id\": image_ids}\n",
    "\n",
    "def crop_bottom_bar(image):\n",
    "    width, height = image.size\n",
    "    if (width != 5376 and height != 3024): return image\n",
    "    bar_height = int(height * 0.05)\n",
    "    cropped_image = F.crop(image, 0, 0, height - bar_height, width)\n",
    "    return cropped_image\n",
    "\n",
    "# custom image dataset\n",
    "class ImagesDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Lambda(crop_bottom_bar),\n",
    "                transforms.Grayscale(num_output_channels=3),\n",
    "                transforms.Resize((480, 480)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        filepath, label = self.data[index]\n",
    "        image = Image.open(filepath).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        sample = {\"image\": image, \"label\": label, \"image_id\": index}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# store feature maps for each layer\n",
    "feature_maps = {}\n",
    "\n",
    "# hook function to save feature maps\n",
    "def hook_fn(module, input, output, name):\n",
    "    feature_maps[name] = output.detach()\n",
    "\n",
    "\n",
    "layers_to_visualize = [\n",
    "    'SpeciesNet/efficientnetv2-m/stem_conv/Conv2D.1',               # very early\n",
    "    'SpeciesNet/efficientnetv2-m/block2a_expand_conv/Conv2D',       # early-mid\n",
    "    'SpeciesNet/efficientnetv2-m/block4a_project_conv/Conv2D',      # mid\n",
    "    'SpeciesNet/efficientnetv2-m/block6b_project_conv/Conv2D',      # late-mid\n",
    "    'SpeciesNet/efficientnetv2-m/top_conv/Conv2D'                   # final conv\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder_path = \"./log\"\n",
    "log_folder_path += \"/species_net_bounded/\"\n",
    "\n",
    "train_csv_file_path = log_folder_path + \"train_scores.csv\"\n",
    "val_csv_file_path = log_folder_path + \"val_scores.csv\"\n",
    "time_csv_file_path = log_folder_path + \"time_per_epoch.csv\"\n",
    "test_csv_file_path = log_folder_path + \"test_scores.csv\"\n",
    "loss_csv_file_path = log_folder_path + \"loss_per_epoch.csv\"\n",
    "\n",
    "num_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2BYwtQR3tI4D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/opcv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from speciesnet import SpeciesNet\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import time\n",
    "import random\n",
    "\n",
    "pretrained_model = \"./pretrained_model.pth\"       # filepath to pretrained model check point\n",
    "speciestnet_model_path = './speciesnet_model'\n",
    "model_folder_path = \"./models/\" + program_id + \"/\"                 # create folder to store optimal model per fold\n",
    "feature_map_folder_path = \"./feature_maps/\" + program_id + \"/\"\n",
    "confusion_matrix_folder_path = \"./cm/\" + program_id + \"/\"\n",
    "os.makedirs(model_folder_path, exist_ok=True)\n",
    "os.makedirs(feature_map_folder_path, exist_ok=True)\n",
    "os.makedirs(confusion_matrix_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fold  index   type\n",
      "0        0    375  train\n",
      "1        0    112  train\n",
      "2        0     35  train\n",
      "3        0    221  train\n",
      "4        0    426  train\n",
      "...    ...    ...    ...\n",
      "3260     4    634   test\n",
      "3261     4    636   test\n",
      "3262     4    641   test\n",
      "3263     4    645   test\n",
      "3264     4    648   test\n",
      "\n",
      "[3265 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# read cross validation indices from stored csv file\n",
    "df_splits = pd.read_csv(\"../crossval_splits.csv\")\n",
    "print(df_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pangolin_indices = []\n",
    "# with open(\"./speciesnet_model/always_crop_99710272_22x8_v12_epoch_00148.labels.txt\", \"r\") as f:\n",
    "#     for idx, line in enumerate(f):\n",
    "#         if \"pangolin\" in line.lower():\n",
    "#             pangolin_indices.append(idx)\n",
    "# print(pangolin_indices)\n",
    "\n",
    "\n",
    "# lines 882, 1405, 1406\n",
    "# 2f336cdf-a62f-4587-a516-6e6c74d07353;mammalia;pholidota;manidae;phataginus;tricuspis;white-bellied pangolin\n",
    "# b1cefdc9-af34-4f28-b077-1186dd6b5072;mammalia;pholidota;manidae;;;pangolin family\n",
    "# ade3ecab-c110-429a-849e-b6afdb290219;mammalia;pholidota;manidae;manis;;pangolin species\n",
    "\n",
    "pangolin_indices = [1404] # family level\n",
    "# pangolin_indices = [1405] # species level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "P5F1ZXhc6nu1",
    "outputId": "23ac6988-d09e-41ca-ca14-bcb563552033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "fold 1 -------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'speciesnet_model/info.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m speciesnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mSpeciesNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeciestnet_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m base_model \u001b[38;5;241m=\u001b[39m speciesnet_model\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# base_model = WrappedModel(base_model)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opcv/lib/python3.9/site-packages/speciesnet/multiprocessing.py:606\u001b[0m, in \u001b[0;36mSpeciesNet.__init__\u001b[0;34m(self, model_name, components, geofence, target_species_txt, combine_predictions_fn, multiprocessing)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m components \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m \u001b[43mSpeciesNetClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_species_txt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_species_txt\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m components \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetector\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m SpeciesNetDetector(model_name)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opcv/lib/python3.9/site-packages/speciesnet/classifier.py:63\u001b[0m, in \u001b[0;36mSpeciesNetClassifier.__init__\u001b[0;34m(self, model_name, target_species_txt)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the classifier resources.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m        with `hf:`) or a local folder to load the model from.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_info \u001b[38;5;241m=\u001b[39m \u001b[43mModelInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Select the best device available.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opcv/lib/python3.9/site-packages/speciesnet/utils.py:102\u001b[0m, in \u001b[0;36mModelInfo.__init__\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     99\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m Path(base_dir)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Load model info.\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minfo.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    103\u001b[0m     info \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fp)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Download detector weights if not provided with the other model files.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'speciesnet_model/info.json'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for fold in df_splits[\"fold\"].unique():   \n",
    "    image_index = 0     # indices for feature maps\n",
    "     \n",
    "    # get the stored indices \n",
    "    train_index = df_splits[(df_splits[\"fold\"] == fold) & (df_splits[\"type\"] == \"train\")][\"index\"].values\n",
    "    val_index = df_splits[(df_splits[\"fold\"] == fold) & (df_splits[\"type\"] == \"val\")][\"index\"].values\n",
    "    test_index = df_splits[(df_splits[\"fold\"] == fold) & (df_splits[\"type\"] == \"test\")][\"index\"].values\n",
    "\n",
    "    print(f\"\\n\\nfold {fold + 1} -------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    min_val_loss = sys.float_info.max\n",
    "    model_name = \"model_fold\" + str(fold + 1) + \".pth\"\n",
    "    model_path = model_folder_path + \"/\" + model_name       # path to store the model checkpoints, name-specific to fold\n",
    "\n",
    "    # split data and get dataloaders\n",
    "    train_data = [data[i] for i in train_index]\n",
    "    val_data = [data[i] for i in val_index]\n",
    "    test_data = [data[i] for i in test_index]\n",
    "\n",
    "    train_dataset = ImagesDataset(train_data)\n",
    "    val_dataset = ImagesDataset(val_data)\n",
    "    test_dataset = ImagesDataset(test_data)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "    # load model\n",
    "    speciesnet_model = SpeciesNet(speciestnet_model_path)\n",
    "    base_model = speciesnet_model.classifier.model\n",
    "    # base_model = WrappedModel(base_model)\n",
    "    base_model.fc = nn.Sequential(\n",
    "        nn.Linear(2048, 100),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(100, 1),  # output a single value for binary classification\n",
    "        # nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    model = base_model.to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.SGD(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),  # only the unfrozen fc layers\n",
    "        lr=0.0001,\n",
    "        momentum=0.9\n",
    "    )\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'fc' in name:          # the head\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # register hooks for each layer\n",
    "    hooks = []\n",
    "    for layer_name in layers_to_visualize:\n",
    "        layer = dict([*model.named_modules()])[layer_name]  # Get the layer by name\n",
    "        hook = layer.register_forward_hook(lambda module, input, output, name=layer_name: hook_fn(module, input, output, name))\n",
    "        hooks.append(hook)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(f\"\\nepoch {epoch}\")\n",
    "\n",
    "        #############################################################################################################################################\n",
    "        # training\n",
    "        #############################################################################################################################################\n",
    "        print(\"TRAINING\")\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        tracking_loss = {}\n",
    "        training_loss = 0\n",
    "        training_num_loss = 0\n",
    "\n",
    "        all_outputs = []\n",
    "        all_labels = []\n",
    "\n",
    "        # iterate through the dataloader batches. tqdm keeps track of progress.\n",
    "        for batch_n, batch in tqdm(\n",
    "            enumerate(train_dataloader), total=len(train_dataloader)\n",
    "        ):\n",
    "            \n",
    "            feature_map_images = batch['image']            \n",
    "\n",
    "            batch[\"image\"] = batch[\"image\"].permute(0, 2, 3, 1)     \n",
    "    \n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].float().to(device)\n",
    "\n",
    "            image_ids = batch['image_id']\n",
    "\n",
    "            # 1) zero out the parameter gradients so that gradients from previous batches are not used in this step\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 2) run the foward step on this batch of images\n",
    "            outputs = model(images).squeeze()\n",
    "\n",
    "            # pangolin_max = outputs[:, pangolin_indices].max(dim=1).values\n",
    "            # other_indices = [i for i in range(outputs.shape[1]) if i not in pangolin_indices]\n",
    "            # other_max = outputs[:, other_indices].max(dim=1).values\n",
    "            # pangolin_logits = pangolin_max - other_max\n",
    "            pangolin_logits = outputs[:, pangolin_indices].logsumexp(dim=1)\n",
    "\n",
    "            pangolin_prob = torch.sigmoid(pangolin_logits)\n",
    "\n",
    "            # 3) compute the loss\n",
    "            loss = criterion(pangolin_logits, labels)\n",
    "\n",
    "            training_loss += loss.item()\n",
    "            training_num_loss += 1\n",
    "\n",
    "            # let's keep track of the loss by epoch\n",
    "            tracking_loss[epoch] = loss.item()\n",
    "\n",
    "            # 4) compute our gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update our weights\n",
    "            optimizer.step()\n",
    "\n",
    "            all_outputs.append(pangolin_prob.detach().cpu())\n",
    "            all_labels.append(labels.detach().cpu())\n",
    "\n",
    "        all_outputs = torch.cat(all_outputs, dim=0)\n",
    "        all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "        train_pred = (all_outputs > 0.5).float()     # get the predicted labels\n",
    "        train_prob = all_outputs                    # get the probability of the positive and negative class\n",
    "        train_true = all_labels             # get the true labels\n",
    "\n",
    "        # print and log scores\n",
    "        training_loss /= training_num_loss\n",
    "        print(f\"\\ttraining loss: {training_loss:.4f}\")\n",
    "        train_print_and_log_scores(fold, epoch, train_true, train_pred, train_prob)\n",
    "\n",
    "        # outputting images for feature extraction\n",
    "        num_images = 10\n",
    "        random_indices = np.random.choice(len(feature_map_images), num_images, replace=False)\n",
    "\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "\n",
    "        label_1_indices = [i for i in range(len(image_ids)) if train_data[image_ids[i]][1] == 1]\n",
    "        label_0_indices = [i for i in range(len(image_ids)) if train_data[image_ids[i]][1] == 0]\n",
    "\n",
    "        sampled_indices = random.sample(label_1_indices, 3) + random.sample(label_0_indices, 7)\n",
    "\n",
    "        for img_idx in sampled_indices:\n",
    "            file_name, label = train_data[image_ids[img_idx]]\n",
    "            fig, axes = plt.subplots(1, len(layers_to_visualize) + 1, figsize=(30, 5))\n",
    "            fig.suptitle(f\"Label: {label}\", fontsize=20)\n",
    "\n",
    "            image = (feature_map_images[img_idx].cpu().numpy().transpose(1, 2, 0)) * std + mean\n",
    "            image = np.clip(image, 0, 1)\n",
    "\n",
    "            # image\n",
    "            axes[0].imshow(image, cmap='gray')\n",
    "            axes[0].set_title(\"original\")\n",
    "            axes[0].axis(\"off\")\n",
    "\n",
    "            for i, layer_name in enumerate(layers_to_visualize):\n",
    "                fmap = feature_maps[layer_name][img_idx]\n",
    "                fmap = fmap.mean(dim=0)\n",
    "                fmap = (fmap - fmap.min()) / (fmap.max() - fmap.min())\n",
    "\n",
    "                if fmap.ndimension() == 3:\n",
    "                    num_channels = fmap.shape[0]\n",
    "                    random_channel = np.random.randint(num_channels)\n",
    "                    fmap_to_show = fmap[random_channel].cpu().numpy()\n",
    "                else:\n",
    "                    random_channel = 0\n",
    "                    fmap_to_show = fmap.cpu().numpy()\n",
    "\n",
    "                fmap_to_show = (fmap_to_show - fmap_to_show.min()) / (fmap_to_show.max() - fmap_to_show.min() + 1e-5)\n",
    "                axes[i + 1].imshow(fmap_to_show, cmap='viridis')\n",
    "\n",
    "                title = '/'.join(layer_name.split('/')[-2:])\n",
    "\n",
    "                axes[i + 1].set_title(f\"{title}\")\n",
    "                axes[i + 1].axis(\"off\")\n",
    "\n",
    "            feature_map_image_path  = feature_map_folder_path + \"feature_map_fold_\" + str(fold + 1) + \"/epoch_\" + str(epoch) + \"/\"      # path to store the feature map images, name-specific to fold and epoch \n",
    "            feature_map_image =  feature_map_image_path + str(image_index) + \".png\"\n",
    "\n",
    "            image_index += 1\n",
    "\n",
    "            os.makedirs(os.path.dirname(feature_map_image), exist_ok=True)\n",
    "            plt.savefig(feature_map_image, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        #############################################################################################################################################\n",
    "        # validation\n",
    "        #############################################################################################################################################\n",
    "        print(\"VALIDATION\")\n",
    "\n",
    "        val_preds_collector = []\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_num_loss = 0\n",
    "\n",
    "        # iterate through dataloader and run the model\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader, total=len(val_dataloader)):\n",
    "                batch[\"image\"] = batch[\"image\"].permute(0, 2, 3, 1)     \n",
    "        \n",
    "                images = batch['image'].to(device)\n",
    "                labels = batch['label'].float().to(device)\n",
    "\n",
    "                image_ids = batch['image_id']\n",
    "                logits = model.forward(images)\n",
    "                \n",
    "                pangolin_logits = logits[:, pangolin_indices].logsumexp(dim=1)\n",
    "                pangolin_prob = torch.sigmoid(pangolin_logits)\n",
    "\n",
    "                loss = criterion(pangolin_logits, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_num_loss += 1\n",
    "\n",
    "                preds_df = pd.DataFrame(\n",
    "                    pangolin_prob.detach().cpu().numpy(),\n",
    "                    index=batch[\"image_id\"],\n",
    "                    columns=[\"prob\"]\n",
    "                )\n",
    "                val_preds_collector.append(preds_df)\n",
    "\n",
    "\n",
    "        val_preds_df = pd.concat(val_preds_collector)\n",
    "        val_preds = (val_preds_df[\"prob\"].values > 0.5).astype(float)     # get the predicted labels\n",
    "        val_true = [label for _, label in val_data]                     # get the true labels\n",
    "        val_prob = val_preds_df[\"prob\"].values                         # get the probability of the positive and negative class\n",
    "\n",
    "        # print scores\n",
    "        val_loss /= val_num_loss\n",
    "        print(f\"\\tvalidation loss: {val_loss:.4f}\")\n",
    "        val_print_and_log_scores(fold, epoch, val_true, val_preds, val_prob)\n",
    "\n",
    "        # log train and val loss\n",
    "        loss_writer.writerow([fold, epoch, training_loss, val_loss])\n",
    "\n",
    "        # check if the current epoch is most optimal based on the current minimum validation loss\n",
    "        if val_loss < min_val_loss:\n",
    "            # save model checkpoint to folder\n",
    "            model_path = os.path.join(model_folder_path, model_name)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "            # update min validation loss value\n",
    "            min_val_loss = val_loss\n",
    "\n",
    "        # get and log the elapsed time for current epoch\n",
    "        epoch_time = time.time() - start_time\n",
    "        time_writer.writerow([fold, epoch, epoch_time])\n",
    "\n",
    "\n",
    "        # thresholds = np.linspace(0.0, 1.0, 200)\n",
    "        # f1s = []\n",
    "        # precisions = []\n",
    "\n",
    "        # for t in thresholds:\n",
    "        #     preds = (val_prob > t).astype(float)\n",
    "        #     f1s.append(f1_score(val_true, preds))\n",
    "\n",
    "        # best_idx = np.argmax(f1s)\n",
    "        # best_thresh = thresholds[best_idx]\n",
    "\n",
    "        # print(f\"optimal threshold: {best_thresh:.3f} (F1: {f1s[best_idx]:.4f})\")\n",
    "\n",
    "\n",
    "\n",
    "    #############################################################################################################################################\n",
    "    # testing\n",
    "    #############################################################################################################################################\n",
    "    print(\"TESTING\")\n",
    "\n",
    "    loaded_model = torch.load(model_path)\n",
    "\n",
    "    test_preds_collector = []\n",
    "    model.eval()\n",
    "\n",
    "    # iterate through dataloader and run the model\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "            batch[\"image\"] = batch[\"image\"].permute(0, 2, 3, 1)      \n",
    "\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].float().to(device)    \n",
    "            image_ids = batch['image_id']\n",
    "\n",
    "            logits = model.forward(images)\n",
    "            \n",
    "            pangolin_logits = logits[:, pangolin_indices].logsumexp(dim=1)\n",
    "            pangolin_prob = torch.sigmoid(pangolin_logits)\n",
    "\n",
    "            preds_df = pd.DataFrame(\n",
    "                pangolin_prob.detach().cpu().numpy(),\n",
    "                index=batch[\"image_id\"],\n",
    "                columns=[\"prob\"]\n",
    "            )\n",
    "            test_preds_collector.append(preds_df)\n",
    "\n",
    "    test_preds_df = pd.concat(test_preds_collector)\n",
    "    test_preds = torch.tensor(test_preds_df[\"prob\"].values > 0.5).long()        # get the predicted labels\n",
    "    test_true = [label for _, label in test_data]                               # get the true labels\n",
    "    test_prob = test_preds_df[\"prob\"].values                                    # get the probability of the positive and negative class\n",
    "\n",
    "    # print and log scores\n",
    "    test_print_and_log_scores(fold, test_true, test_preds, test_prob)\n",
    "\n",
    "    # error analysis on misclassified images\n",
    "    plot_misclassified(fold, test_preds, test_data)\n",
    "\n",
    "    # display confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    plt.title(\"confusion matrix - fold \" + str(fold + 1))\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(\n",
    "        test_true,\n",
    "        test_preds,\n",
    "        ax=ax,\n",
    "        xticks_rotation=90,\n",
    "        colorbar=True,\n",
    "        normalize='true'\n",
    "    )\n",
    "\n",
    "    cm_image_path  = confusion_matrix_folder_path      # path to store the confusion matrix, name-specific to fold \n",
    "    cm_image = cm_image_path + \"cm_fold_\" + str(fold + 1) + \".png\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(cm_image), exist_ok=True)\n",
    "    plt.savefig(cm_image, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # flush writes to logging files\n",
    "    train_csv.flush()\n",
    "    time_csv.flush()\n",
    "    test_csv.flush()\n",
    "    loss_csv.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZG5oysIYGjQF"
   },
   "outputs": [],
   "source": [
    "train_csv.flush()\n",
    "val_csv.flush()\n",
    "time_csv.flush()\n",
    "test_csv.flush()\n",
    "loss_csv.flush()\n",
    "\n",
    "train_csv.close()\n",
    "val_csv.close()\n",
    "time_csv.close()\n",
    "test_csv.close()\n",
    "loss_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "opcv",
   "language": "python",
   "name": "opcv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
